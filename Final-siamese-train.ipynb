{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Data Preparation ---\n",
    "\n",
    "\n",
    "def create_image_pairs(dataset, labels):\n",
    "    \"\"\"Creates positive and negative pairs of images.\"\"\"\n",
    "    digit_indices = [np.where(labels == i)[0] for i in range(10)]\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "\n",
    "    for idx1 in range(len(dataset)):\n",
    "        # Get the current image and its label\n",
    "        x1 = dataset[idx1]\n",
    "        label1 = labels[idx1]\n",
    "\n",
    "        # Add a positive pair\n",
    "        idx2 = np.random.choice(digit_indices[label1])\n",
    "        x2 = dataset[idx2]\n",
    "        pairs.append([x1, x2])\n",
    "        pair_labels.append(1.0)\n",
    "\n",
    "        # Add a negative pair\n",
    "        label2 = np.random.randint(0, 10)\n",
    "        while label2 == label1:\n",
    "            label2 = np.random.randint(0, 10)\n",
    "        idx2 = np.random.choice(digit_indices[label2])\n",
    "        x2 = dataset[idx2]\n",
    "        pairs.append([x1, x2])\n",
    "        pair_labels.append(0.0)\n",
    "\n",
    "    return np.array(pairs), np.array(pair_labels)\n",
    "\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Normalize and extract images and labels\n",
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "train_dataset = train_ds.map(normalize_img)\n",
    "test_dataset = test_ds.map(normalize_img)\n",
    "\n",
    "train_images = np.array([x for x, y in train_dataset])\n",
    "train_labels = np.array([y for x, y in train_dataset])\n",
    "test_images = np.array([x for x, y in test_dataset])\n",
    "test_labels = np.array([y for x, y in test_dataset])\n",
    "\n",
    "# Create training and validation pairs\n",
    "train_pairs, train_y = create_image_pairs(train_images, train_labels)\n",
    "test_pairs, test_y = create_image_pairs(test_images, test_labels)\n",
    "\n",
    "print(f\"Training pairs shape: {train_pairs.shape}\")\n",
    "print(f\"Training labels shape: {train_y.shape}\")\n",
    "\n",
    "# --- 2. Build the Siamese Network ---\n",
    "\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    \"\"\"Creates the base CNN model that produces the embeddings.\"\"\"\n",
    "    input = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(input)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    return tf.keras.Model(input, x)\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"Calculates the euclidean distance between two vectors.\"\"\"\n",
    "    x, y = vects\n",
    "    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "input_shape = (28, 28, 1)\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = tf.keras.layers.Input(shape=input_shape)\n",
    "input_b = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "# Process both inputs with the same base network\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Calculate the distance between the embeddings\n",
    "distance = tf.keras.layers.Lambda(euclidean_distance)([processed_a, processed_b])\n",
    "\n",
    "model = tf.keras.Model([input_a, input_b], distance)\n",
    "model.summary()\n",
    "\n",
    "# --- 3. Contrastive Loss Function ---\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    \"\"\"Contrastive loss function.\n",
    "\n",
    "    y_true: label (1 for similar, 0 for dissimilar)\n",
    "    y_pred: predicted distance from the model\n",
    "    \"\"\"\n",
    "    margin = 1.0\n",
    "    square_pred = tf.square(y_pred)\n",
    "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "# --- 4. Training and Evaluation ---\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=contrastive_loss, optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [train_pairs[:, 0], train_pairs[:, 1]],\n",
    "    train_y,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_y),\n",
    ")\n",
    "\n",
    "# --- 5. Visualize Results ---\n",
    "\n",
    "\n",
    "def display_image_pairs(pairs, labels, predictions, num_items=10):\n",
    "    \"\"\"Displays pairs of images, their true label, and the predicted distance.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(num_items):\n",
    "        ax = plt.subplot(2, num_items, i + 1)\n",
    "        plt.imshow(pairs[i, 0].squeeze(), cmap=\"gray\")\n",
    "        plt.title(f\"Label: {int(labels[i])}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(2, num_items, num_items + i + 1)\n",
    "        plt.imshow(pairs[i, 1].squeeze(), cmap=\"gray\")\n",
    "        plt.title(f\"Pred: {predictions[i][0]:.2f}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get predictions on test pairs\n",
    "predictions = model.predict([test_pairs[:, 0], test_pairs[:, 1]])\n",
    "\n",
    "# Select random pairs to display\n",
    "random_indices = np.random.choice(len(test_y), size=10)\n",
    "display_image_pairs(\n",
    "    test_pairs[random_indices], test_y[random_indices], predictions[random_indices]\n",
    ")\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abeacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a smaller subset of the test data for faster testing\n",
    "test_pairs_subset = test_pairs[:1000]\n",
    "test_y_subset = test_y[:1000]\n",
    "\n",
    "# Get predictions on the subset of test pairs\n",
    "predictions_subset = model.predict([test_pairs_subset[:, 0], test_pairs_subset[:, 1]])\n",
    "\n",
    "# Select random pairs from the subset to display\n",
    "random_indices_subset = np.random.choice(len(test_y_subset), size=10)\n",
    "display_image_pairs(\n",
    "    test_pairs_subset[random_indices_subset],\n",
    "    test_y_subset[random_indices_subset],\n",
    "    predictions_subset[random_indices_subset],\n",
    ")\n",
    "\n",
    "# You can also evaluate the loss on the test subset\n",
    "loss_subset = model.evaluate(\n",
    "    [test_pairs_subset[:, 0], test_pairs_subset[:, 1]], test_y_subset\n",
    ")\n",
    "print(f\"Loss on test subset: {loss_subset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e403bf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.2)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/D-sim/pyprojs/Siamese_Network_Image_Similarity/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"siamese_mnist_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca415f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
